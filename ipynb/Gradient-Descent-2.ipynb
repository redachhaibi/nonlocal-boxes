{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import non_local_boxes\n",
    "\n",
    "# Sugar coating for reloading\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M1[i,i]=1\n",
    "M1[0,0]=0.5\n",
    "M1[0,1]=0.5\n",
    "M1[1,0]=0.5\n",
    "M1[1,1]=0.5\n",
    "\n",
    "M2 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M2[i,i]=1\n",
    "M2[8,8]=0.5\n",
    "M2[8,9]=0.5\n",
    "M2[9,8]=0.5\n",
    "M2[9,9]=0.5\n",
    "\n",
    "M3 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M3[i,i]=1\n",
    "M3[2,2]=0.5\n",
    "M3[2,3]=0.5\n",
    "M3[3,2]=0.5\n",
    "M3[3,3]=0.5\n",
    "\n",
    "M4 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M4[i,i]=1\n",
    "M4[10,10]=0.5\n",
    "M4[10,11]=0.5\n",
    "M4[11,10]=0.5\n",
    "M4[11,11]=0.5\n",
    "\n",
    "M5 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M5[i,i]=1\n",
    "M5[4,4]=0.5\n",
    "M5[4,5]=0.5\n",
    "M5[5,4]=0.5\n",
    "M5[5,5]=0.5\n",
    "\n",
    "M6 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M6[i,i]=1\n",
    "M6[12,12]=0.5\n",
    "M6[12,13]=0.5\n",
    "M6[13,12]=0.5\n",
    "M6[13,13]=0.5\n",
    "\n",
    "M7 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M7[i,i]=1\n",
    "M7[6,6]=0.5\n",
    "M7[6,7]=0.5\n",
    "M7[7,6]=0.5\n",
    "M7[7,7]=0.5\n",
    "\n",
    "M8 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M8[i,i]=1\n",
    "M8[14,14]=0.5\n",
    "M8[14,15]=0.5\n",
    "M8[15,14]=0.5\n",
    "M8[15,15]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_wiring(W):  # W is a 32xn tensor\n",
    "    W = torch.maximum(W, torch.zeros_like(W))  # it outputs the element-wise maximum\n",
    "    W = torch.minimum(W, torch.ones_like(W))   # similarly for minimum\n",
    "\n",
    "    T1 = (torch.abs(W[0,:]-W[1,:]) <= torch.abs(W[8, :] - W[9, :]))\n",
    "    W = T1*torch.tensordot(M1, W, dims=1) + torch.logical_not(T1)*torch.tensordot(M2, W, dims=1)\n",
    "    \n",
    "    T2 = (torch.abs(W[2,:]-W[3,:]) <= torch.abs(W[10, :] - W[11, :]))\n",
    "    W = T2*torch.tensordot(M3, W, dims=1) + torch.logical_not(T2)*torch.tensordot(M4, W, dims=1)\n",
    "\n",
    "    T3 = (torch.abs(W[4,:]-W[5,:]) <= torch.abs(W[12, :] - W[13, :]))\n",
    "    W = T3*torch.tensordot(M5, W, dims=1) + torch.logical_not(T3)*torch.tensordot(M6, W, dims=1)\n",
    "\n",
    "    T4 = (torch.abs(W[6,:]-W[7,:]) <= torch.abs(W[14, :] - W[15, :]))\n",
    "    W = T4*torch.tensordot(M7, W, dims=1) + torch.logical_not(T4)*torch.tensordot(M8, W, dims=1)\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(starting_W, P, Q, learning_rate = 2, nb_iterations = 20):\n",
    "    external_grad = torch.ones(non_local_boxes.evaluate.nb_columns)\n",
    "    W = starting_W\n",
    "    for i in range(nb_iterations):\n",
    "        non_local_boxes.evaluate.phi_flat(W, P, Q).backward(gradient=external_grad)\n",
    "        W = projected_wiring(W + learning_rate*W.grad).detach()  # create a brand new tensor, forgeting the previous gradient\n",
    "        W.requires_grad=True\n",
    "    return W"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test in some triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_color(value, threshold, k, max_box_power_GD):\n",
    "    if value > threshold:\n",
    "        return (0, 0.1*(1-k/max_box_power_GD)+1*(k/max_box_power_GD), 0.1*(1-k/max_box_power_GD)+1*(k/max_box_power_GD))\n",
    "    return \"orangered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_Q(Q, P, W0, color_point, k, max_box_power_GD, learning_rate, nb_iterations, threshold): # Q is a 2x2x2x2 tensor\n",
    "    if color_point == \"orangered\":\n",
    "        W = gradient_descent(W0, non_local_boxes.utils.tensor_to_matrix(Q), P, learning_rate, nb_iterations)\n",
    "        list = non_local_boxes.evaluate.phi_flat(W, non_local_boxes.utils.tensor_to_matrix(Q), P).detach().numpy()\n",
    "        index, value = max(enumerate(list), key=lambda x: x[1])  # find the best value in list\n",
    "        best_wiring = W[:,index].detach()\n",
    "        best_wiring = torch.t(best_wiring.repeat(non_local_boxes.evaluate.nb_columns, 1))\n",
    "        new_Q = non_local_boxes.evaluate.R(best_wiring, non_local_boxes.utils.tensor_to_matrix(Q), P)[:,:,:,:,0]\n",
    "        color_point = new_color(value, threshold, k, max_box_power_GD)\n",
    "        print(value)\n",
    "        best_wiring.requires_grad = True\n",
    "    else:\n",
    "        new_Q = Q\n",
    "        best_wiring = W0\n",
    "    return new_Q, best_wiring, color_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_box_power(Q, P, W0, n, color_point, k, max_box_power_GD, max_box_power, learning_rate, nb_iterations, threshold): # Q is a 2x2x2x2 tensor\n",
    "    for l in range(max_box_power):\n",
    "        if color_point != \"orangered\":\n",
    "            break\n",
    "        Q=non_local_boxes.evaluate.R(W0, non_local_boxes.utils.tensor_to_matrix(Q), P)[:,:,:,:,0]\n",
    "        value = float(non_local_boxes.evaluate.h_flat(Q))\n",
    "        color_point = new_color(value, threshold, k, max_box_power_GD)\n",
    "\n",
    "    return color_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_triangle(Box1, Box1_name, Box2, Box2_name, Box3, Box3_name, box_grid_size, max_box_power_GD, max_box_power, learning_rate, nb_iterations, threshold): # P is a 4x4 tensor\n",
    "    X = torch.tensor([[1,3], [4,1], [4, 5]]).numpy()\n",
    "    triangle = plt.Polygon(X[:3,:], color=\"snow\")\n",
    "    plt.gca().add_patch(triangle)\n",
    "\n",
    "    n = non_local_boxes.evaluate.nb_columns\n",
    "\n",
    "    for i in range(box_grid_size+1):\n",
    "        for j in range(box_grid_size-i+1):\n",
    "            alpha, beta = i/box_grid_size, j/box_grid_size\n",
    "            P = alpha*Box1 + beta*Box2 + (1-alpha-beta)*Box3   # P is a 4x4 matrix\n",
    "            color_point = \"orangered\"\n",
    "\n",
    "            Q=non_local_boxes.utils.matrix_to_tensor(torch.clone(P))  # Q is a 2x2x2x2 tensor \n",
    "            value = float(non_local_boxes.evaluate.h_flat(Q))\n",
    "            color_point = new_color(value, threshold, 0, max_box_power_GD)\n",
    "            best_wiring = non_local_boxes.utils.random_wiring(n)\n",
    "\n",
    "            for k in range(max_box_power_GD-1):\n",
    "                Q, best_wiring, color_point = next_Q(Q, P, best_wiring, color_point, k+1, max_box_power_GD, learning_rate, nb_iterations, threshold)\n",
    "                color_point = test_box_power(Q, P, best_wiring, n, color_point, k+1, max_box_power_GD, max_box_power, learning_rate, nb_iterations, threshold)\n",
    "\n",
    "            plt.plot(X[0,0]*alpha + X[1,0]*beta + X[2,0]*(1-alpha-beta), X[0,1]*alpha + X[1,1]*beta + X[2,1]*(1-alpha-beta), 'o', markersize=3, color=color_point)\n",
    "                    \n",
    "    plt.text(X[0,0], X[0,1]+0.1, Box1_name, horizontalalignment='center')\n",
    "    plt.text(X[1,0]+0.1, X[1,1], Box2_name, verticalalignment='center')\n",
    "    plt.text(X[2,0]+0.1, X[2,1], Box3_name, verticalalignment='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7500001\n",
      "0.7499995\n",
      "0.74999917\n",
      "0.7499999\n",
      "0.7499666\n",
      "0.74951607\n",
      "0.7490216\n",
      "0.7497481\n",
      "0.7499854\n",
      "0.7459803\n",
      "0.748838\n",
      "0.7493319\n",
      "0.7500001\n",
      "0.7486516\n",
      "0.7471202\n",
      "0.74544847\n",
      "0.75000006\n",
      "0.7480225\n",
      "0.7498637\n",
      "0.7499954\n",
      "0.7500001\n",
      "0.75000006\n",
      "0.7500001\n",
      "0.7500001\n",
      "0.7500002\n",
      "0.7458539\n",
      "0.7379234\n",
      "0.7264655\n",
      "0.7500001\n",
      "0.74784696\n",
      "0.7498295\n",
      "0.74998\n",
      "0.7500002\n",
      "0.7372396\n",
      "0.74727196\n",
      "0.74887556\n",
      "0.7500001\n",
      "0.74902225\n",
      "0.74764323\n",
      "0.7485522\n",
      "0.7500001\n",
      "0.7482969\n",
      "0.7498963\n",
      "0.74999374\n",
      "0.7500002\n",
      "0.75000006\n",
      "0.75000006\n",
      "0.7500001\n",
      "0.7500001\n",
      "0.74840164\n",
      "0.75000006\n",
      "0.75000006\n",
      "0.7500001\n",
      "0.75000006\n",
      "0.75000006\n",
      "0.75000006\n",
      "0.7500001\n",
      "0.74630135\n",
      "0.7476718\n",
      "0.75\n",
      "0.7500001\n",
      "0.75000006\n",
      "0.75000006\n",
      "0.75000006\n",
      "0.7500002\n",
      "0.74836665\n",
      "0.7500002\n",
      "0.75000024\n",
      "0.7500001\n",
      "0.7089485\n",
      "0.75\n",
      "0.75\n",
      "0.7500001\n",
      "0.75\n",
      "0.7499999\n",
      "0.7499999\n",
      "0.75000006\n",
      "0.74999994\n",
      "0.74704474\n",
      "0.74999994\n",
      "0.7500001\n",
      "0.75\n",
      "0.75\n",
      "0.75000006\n",
      "0.7500001\n",
      "0.75\n",
      "0.74999994\n",
      "0.74999994\n",
      "0.7500001\n",
      "0.75\n",
      "0.7500001\n",
      "0.75000006\n",
      "0.7500001\n",
      "0.7492763\n",
      "0.7499496\n",
      "0.74999654\n",
      "0.7500002\n",
      "0.74999684\n",
      "0.75000006\n",
      "0.75000024\n",
      "0.7500001\n",
      "0.75\n",
      "0.75\n",
      "0.74999994\n",
      "0.7500001\n",
      "0.74772906\n",
      "0.74999994\n",
      "0.7499999\n",
      "0.7500001\n",
      "0.74601597\n",
      "0.7468925\n",
      "0.7499999\n",
      "0.7500002\n",
      "0.7343044\n",
      "0.7470995\n",
      "0.748365\n",
      "0.7500002\n",
      "0.7469979\n",
      "0.75000006\n",
      "0.7500001\n",
      "0.7500001\n",
      "0.74813926\n",
      "0.75\n",
      "0.75\n",
      "0.7500001\n",
      "0.7492754\n",
      "0.7498728\n",
      "0.7499802\n",
      "0.7500002\n",
      "0.74854827\n",
      "0.7496397\n",
      "0.74991584\n",
      "0.7500001\n",
      "0.75000006\n",
      "0.75\n",
      "0.75\n",
      "0.7500001\n",
      "0.7489311\n",
      "0.7496921\n",
      "0.7496839\n",
      "0.7500001\n",
      "0.7402026\n",
      "0.7481349\n",
      "0.7492616\n",
      "0.75\n",
      "0.74855804\n",
      "0.7485647\n",
      "0.74870884\n",
      "0.75000006\n",
      "0.74795264\n",
      "0.7486392\n",
      "0.7496384\n",
      "0.75\n",
      "0.7493661\n",
      "0.7499934\n",
      "0.7499999\n",
      "0.7499594\n",
      "0.7480811\n",
      "0.749468\n",
      "0.7499874\n",
      "0.7500001\n",
      "0.75000006\n",
      "0.74999994\n",
      "0.75\n",
      "0.7511743\n",
      "0.7550853\n",
      "0.75595903\n",
      "0.75602144\n",
      "0.75250214\n",
      "0.7436704\n",
      "0.749807\n",
      "0.7505064\n",
      "0.75124174\n",
      "0.7487233\n",
      "0.747569\n",
      "0.7465628\n",
      "0.75219053\n",
      "0.7450875\n",
      "0.7504301\n",
      "0.75153667\n",
      "0.75364345\n",
      "0.7552275\n",
      "0.7552468\n",
      "0.7552893\n",
      "0.75108814\n",
      "0.74900717\n",
      "0.7482982\n",
      "0.7480593\n",
      "0.7537616\n",
      "0.7527238\n",
      "0.75124925\n",
      "0.74968034\n",
      "0.7536184\n",
      "0.74993587\n",
      "0.746893\n",
      "0.74456537\n",
      "0.75183415\n",
      "0.7494846\n",
      "0.7507588\n",
      "0.75084627\n",
      "0.7520405\n",
      "0.7483374\n",
      "0.74777555\n",
      "0.7471023\n",
      "0.7522726\n",
      "0.7504904\n",
      "0.7498664\n",
      "0.7494979\n",
      "0.7530078\n",
      "0.74893415\n",
      "0.74597764\n",
      "0.7454351\n",
      "0.7519412\n",
      "0.7519226\n",
      "0.7513191\n",
      "0.7520339\n",
      "0.7523314\n",
      "0.7510439\n",
      "0.75275326\n",
      "0.75355625\n",
      "0.7518928\n",
      "0.7509852\n",
      "0.75055146\n",
      "0.7503127\n",
      "0.7524132\n",
      "0.75138617\n",
      "0.7508405\n",
      "0.7505148\n",
      "0.752205\n",
      "0.7455619\n",
      "0.75237864\n",
      "0.7529922\n",
      "0.7516159\n",
      "0.7509759\n",
      "0.7511588\n",
      "0.75145197\n",
      "0.7517509\n",
      "0.7465779\n",
      "0.74920404\n",
      "0.75160086\n",
      "0.7524778\n",
      "0.7506697\n",
      "0.75048226\n",
      "0.7501265\n",
      "0.7509433\n",
      "0.74884075\n",
      "0.75095075\n",
      "0.75152457\n",
      "0.7519096\n",
      "0.74409926\n",
      "0.7436045\n",
      "0.7434206\n",
      "0.7521527\n",
      "0.75005203\n",
      "0.7505394\n",
      "0.750563\n",
      "0.7516477\n",
      "0.7506279\n",
      "0.75062776\n",
      "0.75062776\n",
      "0.7538463\n",
      "0.75209504\n",
      "0.7521169\n",
      "0.7513479\n",
      "0.7512666\n",
      "0.75053704\n",
      "0.7505281\n",
      "0.75276446\n",
      "0.7516046\n",
      "0.75023866\n",
      "0.74982876\n",
      "0.7497563\n",
      "0.7529001\n",
      "0.7515592\n",
      "0.75211686\n",
      "0.75239\n",
      "0.752796\n",
      "0.7528364\n",
      "0.75280046\n",
      "0.75279814\n",
      "0.7519995\n",
      "0.7509836\n",
      "0.75188136\n",
      "0.75264496\n",
      "0.75208837\n",
      "0.7513551\n",
      "0.7508986\n",
      "0.75052404\n",
      "0.7534178\n",
      "0.75081974\n",
      "0.7517162\n",
      "0.7499684\n",
      "0.75153685\n",
      "0.7491779\n",
      "0.7479011\n",
      "0.74758506\n",
      "0.75284404\n",
      "0.7490286\n",
      "0.7463367\n",
      "0.7430022\n",
      "0.751905\n",
      "0.75216717\n",
      "0.7535296\n",
      "0.75568694\n",
      "0.75169986\n",
      "0.75176245\n",
      "0.7535944\n",
      "0.7542341\n",
      "0.7539878\n",
      "0.7511733\n",
      "0.75077194\n",
      "0.7490181\n",
      "0.7523174\n",
      "0.7477299\n",
      "0.74988306\n",
      "0.74996847\n",
      "0.75195247\n",
      "0.74860334\n",
      "0.74744827\n",
      "0.7457439\n",
      "0.7542363\n",
      "0.7471823\n",
      "0.7486393\n",
      "0.7494849\n",
      "0.7587041\n",
      "0.7548944\n",
      "0.76396495\n",
      "0.7626514\n",
      "0.7597708\n",
      "0.7591099\n",
      "0.75853103\n",
      "0.757898\n",
      "0.7590016\n",
      "0.74931836\n",
      "0.74913085\n",
      "0.74909955\n",
      "0.7604666\n",
      "0.758038\n",
      "0.7619804\n",
      "0.75975376\n",
      "0.7604916\n",
      "0.7589501\n",
      "0.7576605\n",
      "0.7568895\n",
      "0.76079834\n",
      "0.75192297\n",
      "0.75266695\n",
      "0.751626\n",
      "0.7600577\n",
      "0.7563232\n",
      "0.74743414\n",
      "0.74298775\n",
      "0.76396006\n",
      "0.7596377\n",
      "0.7603178\n",
      "0.75782764\n",
      "0.7619029\n",
      "0.76045406\n",
      "0.7662123\n",
      "0.7675511\n",
      "0.7597601\n",
      "0.75303656\n",
      "0.7515219\n",
      "0.7508093\n",
      "0.7583206\n",
      "0.7548173\n",
      "0.7540405\n",
      "0.7523727\n",
      "0.7554156\n",
      "0.7537401\n",
      "0.75254405\n",
      "0.75174356\n",
      "0.7563801\n",
      "0.748881\n",
      "0.74018747\n",
      "0.742527\n",
      "0.7564932\n",
      "0.7559024\n",
      "0.7567086\n",
      "0.7572849\n",
      "0.75594425\n",
      "0.750103\n",
      "0.74418306\n",
      "0.7355602\n",
      "0.75617015\n",
      "0.75128174\n",
      "0.74827147\n",
      "0.74629706\n",
      "0.75581723\n",
      "0.73896873\n",
      "0.7367141\n",
      "0.7407628\n",
      "0.75561595\n",
      "0.7509447\n",
      "0.75277936\n",
      "0.7543737\n",
      "0.75528175\n",
      "0.7517038\n",
      "0.75366133\n",
      "0.75541604\n",
      "0.75650126\n",
      "0.749881\n",
      "0.74335706\n",
      "0.74127376\n",
      "0.75418323\n",
      "0.75559855\n",
      "0.758123\n",
      "0.7612581\n",
      "0.75620335\n",
      "0.7524385\n",
      "0.75314635\n",
      "0.75581574\n",
      "0.7554461\n",
      "0.7514657\n",
      "0.7500008\n",
      "0.7501277\n",
      "0.75741816\n",
      "0.7551359\n",
      "0.7550414\n",
      "0.75446665\n",
      "0.75455946\n",
      "0.7544614\n",
      "0.7573128\n",
      "0.76104397\n",
      "0.75612605\n",
      "0.74565053\n",
      "0.74855316\n",
      "0.74922615\n",
      "0.7586321\n",
      "0.756906\n",
      "0.7559955\n",
      "0.75541586\n",
      "0.7575781\n",
      "0.7320757\n",
      "0.72145045\n",
      "0.726161\n",
      "0.75842726\n",
      "0.7540341\n",
      "0.7525\n",
      "0.7549525\n",
      "0.7575569\n",
      "0.7498287\n",
      "0.75012875\n",
      "0.7515496\n",
      "0.76003695\n",
      "0.76106375\n",
      "0.7624252\n",
      "0.76281136\n",
      "0.758628\n",
      "0.7573055\n",
      "0.75762\n",
      "0.7582392\n",
      "0.7564156\n",
      "0.75675565\n",
      "0.75887865\n",
      "0.76063466\n",
      "0.75835156\n",
      "0.754336\n",
      "0.7530813\n",
      "0.7518613\n",
      "0.7596703\n",
      "0.75043344\n",
      "0.75509304\n",
      "0.75843555\n",
      "0.76000345\n",
      "0.7490376\n",
      "0.75159204\n",
      "0.7481365\n",
      "0.7594445\n",
      "0.75471234\n",
      "0.753256\n",
      "0.75199676\n",
      "0.76377445\n",
      "0.76200575\n",
      "0.76139885\n",
      "0.7603278\n",
      "0.7592301\n",
      "0.75901836\n",
      "0.76066595\n",
      "0.76144725\n",
      "0.77356184\n",
      "0.767506\n",
      "0.7660475\n",
      "0.7655894\n",
      "0.77447045\n",
      "0.76971495\n",
      "0.777545\n",
      "0.7735789\n",
      "0.7664444\n",
      "0.7649904\n",
      "0.76656455\n",
      "0.76687795\n",
      "0.77617025\n",
      "0.76793605\n",
      "0.77446264\n",
      "0.7685808\n",
      "0.7663005\n",
      "0.7426999\n",
      "0.74475783\n",
      "0.7413752\n",
      "0.76508296\n",
      "0.76230013\n",
      "0.7636848\n",
      "0.763843\n",
      "0.7669758\n",
      "0.76235044\n",
      "0.77003205\n",
      "0.7675599\n",
      "0.7660149\n",
      "0.76205695\n",
      "0.76150465\n",
      "0.75994086\n",
      "0.7634491\n",
      "0.7560532\n",
      "0.75437486\n",
      "0.75329083\n",
      "0.76272684\n",
      "0.75903815\n",
      "0.7563418\n",
      "0.7543682\n",
      "0.76485115\n",
      "0.7477778\n",
      "0.7408369\n",
      "0.73968214\n",
      "0.7636018\n",
      "0.7611596\n",
      "0.7609576\n",
      "0.75982815\n",
      "0.7622721\n",
      "0.7560621\n",
      "0.75268334\n",
      "0.75110835\n",
      "0.76469815\n",
      "0.75588983\n",
      "0.7547102\n",
      "0.75181854\n",
      "0.7605413\n",
      "0.75489193\n",
      "0.75271934\n",
      "0.75154746\n",
      "0.75981617\n",
      "0.7546266\n",
      "0.75271815\n",
      "0.751597\n",
      "0.7602109\n",
      "0.76021093\n",
      "0.76021093\n",
      "0.7602109\n",
      "0.75970566\n",
      "0.7597343\n",
      "0.7599696\n",
      "0.76001424\n",
      "0.7651099\n",
      "0.7619244\n",
      "0.75591373\n",
      "0.75342494\n",
      "0.75954854\n",
      "0.76335365\n",
      "0.76848304\n",
      "0.76874983\n",
      "0.76078427\n",
      "0.7511379\n",
      "0.7555201\n",
      "0.75741273\n",
      "0.7588842\n",
      "0.73951435\n",
      "0.7314631\n",
      "0.7449322\n",
      "0.760092\n",
      "0.75543475\n",
      "0.7531455\n",
      "0.751744\n",
      "0.762637\n",
      "0.7579852\n",
      "0.7585866\n",
      "0.7613574\n",
      "0.7615122\n",
      "0.7594725\n",
      "0.75736487\n",
      "0.75569177\n",
      "0.76220787\n",
      "0.748023\n",
      "0.748966\n",
      "0.7474166\n",
      "0.7654481\n",
      "0.7604323\n",
      "0.7457086\n",
      "0.74364454\n",
      "0.7681805\n",
      "0.7605451\n",
      "0.7601279\n",
      "0.75765777\n",
      "0.7666307\n",
      "0.7597345\n",
      "0.7597817\n",
      "0.7584627\n",
      "0.7639692\n",
      "0.7595353\n",
      "0.76231277\n",
      "0.7619769\n",
      "0.76898676\n",
      "0.76109505\n",
      "0.7665027\n",
      "0.7622847\n",
      "0.7714395\n",
      "0.765587\n",
      "0.77189237\n",
      "0.76778424\n",
      "0.7680543\n",
      "0.7629541\n"
     ]
    }
   ],
   "source": [
    "draw_triangle(\n",
    "    Box1=non_local_boxes.utils.PR,\n",
    "    Box1_name = \"PR\",\n",
    "    Box2=non_local_boxes.utils.P_0,\n",
    "    Box2_name = \"P0\",\n",
    "    Box3 = non_local_boxes.utils.P_1,\n",
    "    Box3_name = \"P1\",\n",
    "    box_grid_size = 40,\n",
    "    max_box_power_GD = 5,\n",
    "    max_box_power = 70,\n",
    "    learning_rate = 2,\n",
    "    nb_iterations = 20,\n",
    "    threshold = (3 + float(torch.sqrt(torch.tensor(6))))/6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_boxes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc316f9929218361e7d645a202e8c2b79a1175dfee9b41dd9aa3806e9995da6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
