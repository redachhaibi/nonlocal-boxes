{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import non_local_boxes\n",
    "\n",
    "# Sugar coating for reloading\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic Gradient Descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Maximization under constraints\n",
    "\n",
    "As we maximize under constraints, we need the orthogonal projection onto the unit hypercube $[0,1]^{32}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def projected_wiring_basic(W):  # W is a 32xn tensor\n",
    "#     W = torch.maximum(W, torch.zeros_like(W))  # it outputs the element-wise maximum\n",
    "#     W = torch.minimum(W, torch.ones_like(W))   # similarly for minimum\n",
    "#     return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def projected_wiring_old(W):  # W is a 32xn tensor\n",
    "#     W = torch.maximum(W, torch.zeros_like(W))  # it outputs the element-wise maximum\n",
    "#     W = torch.minimum(W, torch.ones_like(W))   # similarly for minimum\n",
    "\n",
    "#     # Then we verify the 4 equalities of (5)\n",
    "#     for alpha in range(non_local_boxes.evaluate.nb_columns):\n",
    "#         #1\n",
    "#         if abs(W[0, alpha] - W[1, alpha]) <= abs(W[8, alpha] - W[9, alpha]):\n",
    "#             W[0, alpha] = (W[0, alpha]+W[1, alpha])/2\n",
    "#             W[1, alpha] = W[0, alpha]\n",
    "#         else:\n",
    "#             W[8, alpha] = (W[8, alpha]+W[9, alpha])/2\n",
    "#             W[9, alpha] = W[8, alpha]\n",
    "            \n",
    "#         #2\n",
    "#         if abs(W[2, alpha] - W[3, alpha]) <= abs(W[10, alpha] - W[11, alpha]):\n",
    "#             W[2, alpha] = (W[2, alpha]+W[3, alpha])/2\n",
    "#             W[3, alpha] = W[2, alpha]\n",
    "#         else:\n",
    "#             W[10, alpha] = (W[10, alpha]+W[11, alpha])/2\n",
    "#             W[11, alpha] = W[10, alpha]\n",
    "            \n",
    "#         #3\n",
    "#         if abs(W[4, alpha] - W[5, alpha]) <= abs(W[12, alpha] - W[13, alpha]):\n",
    "#             W[4, alpha] = (W[4, alpha]+W[5, alpha])/2\n",
    "#             W[5, alpha] = W[4, alpha]\n",
    "#         else:\n",
    "#             W[12, alpha] = (W[12, alpha]+W[13, alpha])/2\n",
    "#             W[13, alpha] = W[12, alpha]\n",
    "                \n",
    "#         #4\n",
    "#         if abs(W[6, alpha] - W[7, alpha]) <= abs(W[14, alpha] - W[15, alpha]):\n",
    "#             W[6, alpha] = (W[6, alpha]+W[7, alpha])/2\n",
    "#             W[7, alpha] = W[6, alpha]\n",
    "#         else:\n",
    "#             W[14, alpha] = (W[14, alpha]+W[15, alpha])/2\n",
    "#             W[15, alpha] = W[14, alpha]\n",
    "\n",
    "#     return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M1[i,i]=1\n",
    "M1[0,0]=0.5\n",
    "M1[0,1]=0.5\n",
    "M1[1,0]=0.5\n",
    "M1[1,1]=0.5\n",
    "\n",
    "M2 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M2[i,i]=1\n",
    "M2[8,8]=0.5\n",
    "M2[8,9]=0.5\n",
    "M2[9,8]=0.5\n",
    "M2[9,9]=0.5\n",
    "\n",
    "M3 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M3[i,i]=1\n",
    "M3[2,2]=0.5\n",
    "M3[2,3]=0.5\n",
    "M3[3,2]=0.5\n",
    "M3[3,3]=0.5\n",
    "\n",
    "M4 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M4[i,i]=1\n",
    "M4[10,10]=0.5\n",
    "M4[10,11]=0.5\n",
    "M4[11,10]=0.5\n",
    "M4[11,11]=0.5\n",
    "\n",
    "M5 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M5[i,i]=1\n",
    "M5[4,4]=0.5\n",
    "M5[4,5]=0.5\n",
    "M5[5,4]=0.5\n",
    "M5[5,5]=0.5\n",
    "\n",
    "M6 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M6[i,i]=1\n",
    "M6[12,12]=0.5\n",
    "M6[12,13]=0.5\n",
    "M6[13,12]=0.5\n",
    "M6[13,13]=0.5\n",
    "\n",
    "M7 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M7[i,i]=1\n",
    "M7[6,6]=0.5\n",
    "M7[6,7]=0.5\n",
    "M7[7,6]=0.5\n",
    "M7[7,7]=0.5\n",
    "\n",
    "M8 = torch.zeros(32, 32)\n",
    "for i in range(32):\n",
    "    M8[i,i]=1\n",
    "M8[14,14]=0.5\n",
    "M8[14,15]=0.5\n",
    "M8[15,14]=0.5\n",
    "M8[15,15]=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_wiring(W):  # W is a 32xn tensor\n",
    "    W = torch.maximum(W, torch.zeros_like(W))  # it outputs the element-wise maximum\n",
    "    W = torch.minimum(W, torch.ones_like(W))   # similarly for minimum\n",
    "\n",
    "    T1 = (torch.abs(W[0,:]-W[1,:]) <= torch.abs(W[8, :] - W[9, :]))\n",
    "    # If T1[i] is True: W[:,i] becomes M1 . W[:,i]\n",
    "    # Otherwise: W[:,i] becomes M2 . W[:,i]\n",
    "    W = T1*torch.tensordot(M1, W, dims=1) + torch.logical_not(T1)*torch.tensordot(M2, W, dims=1)\n",
    "    \n",
    "    T2 = (torch.abs(W[2,:]-W[3,:]) <= torch.abs(W[10, :] - W[11, :]))\n",
    "    # If T2[i] is True: W[:,i] becomes M3 . W[:,i]\n",
    "    # Otherwise: W[:,i] becomes M4 . W[:,i]\n",
    "    W = T2*torch.tensordot(M3, W, dims=1) + torch.logical_not(T2)*torch.tensordot(M4, W, dims=1)\n",
    "\n",
    "    T3 = (torch.abs(W[4,:]-W[5,:]) <= torch.abs(W[12, :] - W[13, :]))\n",
    "    # If T3[i] is True: W[:,i] becomes M5 . W[:,i]\n",
    "    # Otherwise: W[:,i] becomes M6 . W[:,i]\n",
    "    W = T3*torch.tensordot(M5, W, dims=1) + torch.logical_not(T3)*torch.tensordot(M6, W, dims=1)\n",
    "\n",
    "    T4 = (torch.abs(W[6,:]-W[7,:]) <= torch.abs(W[14, :] - W[15, :]))\n",
    "    # If T4[i] is True: W[:,i] becomes M7 . W[:,i]\n",
    "    # Otherwise: W[:,i] becomes M8 . W[:,i]\n",
    "    W = T4*torch.tensordot(M7, W, dims=1) + torch.logical_not(T4)*torch.tensordot(M8, W, dims=1)\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = non_local_boxes.utils.random_wiring(non_local_boxes.evaluate.nb_columns).detach()\n",
    "# projected_wiring(W) == projected_wiring_old(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = non_local_boxes.utils.W_BS09(non_local_boxes.evaluate.nb_columns).detach()\n",
    "P = non_local_boxes.utils.SR\n",
    "Q = non_local_boxes.utils.PR\n",
    "float(non_local_boxes.evaluate.phi_flat(W, P, Q)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(starting_W, P, Q, learning_rate = 2, nb_steps = 20):\n",
    "    external_grad = torch.ones(non_local_boxes.evaluate.nb_columns)\n",
    "    W = starting_W\n",
    "    for i in range(nb_steps):\n",
    "        non_local_boxes.evaluate.phi_flat(W, P, Q).backward(gradient=external_grad)\n",
    "        W = projected_wiring(W + learning_rate*W.grad).detach()  # create a brand new tensor, forgeting the previous gradient\n",
    "        W.requires_grad=True\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iterating...)\n",
      "\n",
      "Number of tested wirings:  1000\n",
      "--> Min:     0.747215\n",
      "--> Av.:     0.7862032339572906\n",
      "--> Max:     1.0\n",
      "Duration:  0.2938542366027832 s\n",
      "\n",
      "-----\n",
      "The best wiring is:\n",
      " [0.59112215 0.59112215 0.9105094  0.9105094  0.08339131 0.7045876\n",
      " 0.72113067 0.72113067 0.         1.         1.         0.\n",
      " 1.         1.         0.         0.         1.         0.\n",
      " 1.         0.         0.         1.         0.         1.\n",
      " 1.         0.         0.         1.         1.         0.\n",
      " 1.         0.        ]\n",
      "-----\n",
      "f_1(x,a2) =  0.3193872570991516 x ⊕  0.0 a2 ⊕  0.0 x*a2 ⊕  0.5911221504211426\n",
      "g_1(y,b2) =  0.637739360332489 y ⊕  0.6211962699890137 b2 ⊕  1.3788037300109863 y*b2 ⊕  0.08339130878448486\n",
      "f_2(x,a1) =  1.0 x ⊕  1.0 a1 ⊕  0.0 x*a1 ⊕  0.0\n",
      "g_2(y,b1) =  1.0 y ⊕  0.0 b1 ⊕  0.0 y*b1 ⊕  1.0\n",
      "f_3(x,a1,a2) =  1.0 x ⊕  0.0 a1 ⊕  1.0 a2 ⊕  1.0 x*a1 ⊕  1.0 x*a2 ⊕  0.0 a1*a2 ⊕  0.0 x*a1*a2 ⊕  1.0\n",
      "g_3(y,b1,b2) =  0.0 y ⊕  1.0 b1 ⊕  1.0 b2 ⊕  0.0 y*b1 ⊕  1.0 y*b2 ⊕  0.0 b1*b2 ⊕  0.0 y*b1*b2 ⊕  1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "starting_W = non_local_boxes.utils.random_wiring(non_local_boxes.evaluate.nb_columns)\n",
    "P = non_local_boxes.utils.SR\n",
    "Q = non_local_boxes.utils.PR\n",
    "learning_rate = 2\n",
    "nb_steps = 20\n",
    "\n",
    "\n",
    "# Gradient Descent\n",
    "print(\"(Iterating...)\")\n",
    "tic = time.time()\n",
    "W = gradient_descent(starting_W, P, Q, learning_rate, nb_steps)\n",
    "toc = time.time()\n",
    "\n",
    "\n",
    "# Result\n",
    "list = non_local_boxes.evaluate.phi_flat(W, P, Q).detach().numpy()\n",
    "print(\"\")\n",
    "print(\"Number of tested wirings: \", len(list))\n",
    "print(\"--> Min:    \", min(list))\n",
    "print(\"--> Av.:    \", sum(list)/len(list))\n",
    "index, value = max(enumerate(list), key=lambda x: x[1])\n",
    "best_wiring = W[:,index].detach().numpy()\n",
    "print(\"--> Max:    \", value)\n",
    "print(\"Duration: \", (toc-tic)*1e0, \"s\")\n",
    "print(\"\")\n",
    "print(\"-----\")\n",
    "print(\"The best wiring is:\\n\", best_wiring)\n",
    "print(\"-----\")\n",
    "non_local_boxes.utils.wiring_to_functions(best_wiring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.24272715, 0.12160056, 0.9498826 , 0.02322189, 0.39412087,\n",
    "       0.39412087, 0.83709   , 0.52627677, 0.        , 0.        ,\n",
    "       1.        , 1.        , 0.        , 0.        , 1.        ,\n",
    "       1.        , 1.        , 0.        , 1.        , 0.        ,\n",
    "       1.        , 0.        , 1.        , 0.        , 1.        ,\n",
    "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
    "       1.        , 0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.t(torch.tensor([[0., 0., 1. , 0., 0.,\n",
    "       0., 1.   , 0.5 , 0.        , 0.        ,\n",
    "       1.        , 1.        , 0.        , 0.        , 1.        ,\n",
    "       1.        , 1.        , 0.        , 1.        , 0.        ,\n",
    "       1.        , 0.        , 1.        , 0.        , 1.        ,\n",
    "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
    "       1.        , 0.        ]]))\n",
    "\n",
    "P = non_local_boxes.utils.SR\n",
    "Q = non_local_boxes.utils.PR\n",
    "float(non_local_boxes.evaluate.phi_flat(W, P, Q)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Test in the triangle PR-P0-P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[1,3], [4,1], [4, 5]]).numpy()\n",
    "\n",
    "triangle = plt.Polygon(X[:3,:], color=\"snow\")\n",
    "plt.gca().add_patch(triangle)\n",
    "\n",
    "number_steps = 10\n",
    "threshold = (3 + float(torch.sqrt(torch.tensor(6))))/6\n",
    "number_products = 10\n",
    "\n",
    "PR = non_local_boxes.utils.PR\n",
    "P_0 = non_local_boxes.utils.P_0\n",
    "P_1 = non_local_boxes.utils.P_1\n",
    "W_BS09 = non_local_boxes.utils.W_BS09(non_local_boxes.evaluate.nb_columns).detach()\n",
    "W_random = non_local_boxes.utils.random_wiring(non_local_boxes.evaluate.nb_columns)\n",
    "\n",
    "for i in range(number_steps+1):\n",
    "    for j in range(number_steps-i+1):\n",
    "        alpha = i/number_steps\n",
    "        beta = j/number_steps\n",
    "        P = alpha*PR + beta*P_0 + (1-alpha-beta)*P_1   # P is a 4x4 matrix\n",
    "        color_point = \"orangered\"\n",
    "\n",
    "        # Given a box P, we look for the W maximizing P x_W P\n",
    "        W = gradient_descent(W_random, P, P, learning_rate=2, nb_steps=20)\n",
    "        list = non_local_boxes.evaluate.phi_flat(W, P, P).detach().numpy()\n",
    "        index, value = max(enumerate(list), key=lambda x: x[1])\n",
    "        best_wiring = W[:,index].detach()\n",
    "        print(value)\n",
    "        \n",
    "        Q=torch.clone(P)\n",
    "        Q=non_local_boxes.utils.matrix_to_tensor(Q)  # Q is a 2x2x2x2 tensor \n",
    "        for k in range(number_products+1):\n",
    "            if non_local_boxes.evaluate.h_flat(Q)[0] > threshold:\n",
    "                color_point = (0, 0.1*(1-k/number_products)+1*(k/number_products), 0.1*(1-k/number_products)+1*(k/number_products))\n",
    "                break\n",
    "            #Q2=Q.copy()\n",
    "            Q=non_local_boxes.evaluate.R(W, non_local_boxes.utils.tensor_to_matrix(Q), P)[:,:,:,:,0]\n",
    "\n",
    "        plt.plot(X[0,0]*alpha + X[1,0]*beta + X[2,0]*(1-alpha-beta), X[0,1]*alpha + X[1,1]*beta + X[2,1]*(1-alpha-beta), 'o', markersize=3, color=color_point)\n",
    "                \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_boxes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc316f9929218361e7d645a202e8c2b79a1175dfee9b41dd9aa3806e9995da6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
