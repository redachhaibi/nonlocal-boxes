{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import non_local_boxes\n",
    "\n",
    "# Sugar coating for reloading\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic Gradient Descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Maximization under constraints\n",
    "\n",
    "As we maximize under constraints, we need the orthogonal projection onto the unit hypercube $[0,1]^{32}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_wiring_basic(W):  # W is a 32xn tensor\n",
    "    W = torch.maximum(W, torch.zeros_like(W))  # it outputs the element-wise maximum\n",
    "    W = torch.minimum(W, torch.ones_like(W))   # similarly for minimum\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_wiring(W):  # W is a 32xn tensor\n",
    "    W = torch.maximum(W, torch.zeros_like(W))  # it outputs the element-wise maximum\n",
    "    W = torch.minimum(W, torch.ones_like(W))   # similarly for minimum\n",
    "\n",
    "    # Then we verify the 4 equalities of (5)\n",
    "    for alpha in range(non_local_boxes.evaluate.nb_columns):\n",
    "        #1\n",
    "        if abs(W[0, alpha] - W[1, alpha]) <= abs(W[8, alpha] - W[9, alpha]):\n",
    "            W[0, alpha] = (W[0, alpha]+W[1, alpha])/2\n",
    "            W[1, alpha] = W[0, alpha]\n",
    "        else:\n",
    "            W[8, alpha] = (W[8, alpha]+W[9, alpha])/2\n",
    "            W[9, alpha] = W[8, alpha]\n",
    "            \n",
    "        #2\n",
    "        if abs(W[2, alpha] - W[3, alpha]) <= abs(W[10, alpha] - W[11, alpha]):\n",
    "            W[2, alpha] = (W[2, alpha]+W[3, alpha])/2\n",
    "            W[3, alpha] = W[2, alpha]\n",
    "        else:\n",
    "            W[10, alpha] = (W[10, alpha]+W[11, alpha])/2\n",
    "            W[11, alpha] = W[10, alpha]\n",
    "            \n",
    "        #3\n",
    "        if abs(W[4, alpha] - W[5, alpha]) <= abs(W[12, alpha] - W[13, alpha]):\n",
    "            W[4, alpha] = (W[4, alpha]+W[5, alpha])/2\n",
    "            W[5, alpha] = W[4, alpha]\n",
    "        else:\n",
    "            W[12, alpha] = (W[12, alpha]+W[13, alpha])/2\n",
    "            W[13, alpha] = W[12, alpha]\n",
    "                \n",
    "        #4\n",
    "        if abs(W[6, alpha] - W[7, alpha]) <= abs(W[14, alpha] - W[15, alpha]):\n",
    "            W[6, alpha] = (W[6, alpha]+W[7, alpha])/2\n",
    "            W[7, alpha] = W[6, alpha]\n",
    "        else:\n",
    "            W[14, alpha] = (W[14, alpha]+W[15, alpha])/2\n",
    "            W[15, alpha] = W[14, alpha]\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778342604637146"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = non_local_boxes.utils.random_wiring(3).detach()\n",
    "torch.abs(W[0,:]-W[1,:]) <= torch.ones(3)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(\"Hello\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating...\n",
      "\n",
      "Number of tested wirings:  1000\n",
      "--> Min:  0.74883735\n",
      "--> Av.:  0.7967481325864791\n",
      "--> Max:  1.0\n",
      "Duration:  201.96199417114258 ms\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "starting_W = non_local_boxes.utils.random_wiring(non_local_boxes.evaluate.nb_columns)\n",
    "nb_steps = 20\n",
    "learning_rate = 2\n",
    "\n",
    "P = non_local_boxes.utils.SR\n",
    "Q = non_local_boxes.utils.PR\n",
    "external_grad = torch.ones(non_local_boxes.evaluate.nb_columns)\n",
    "\n",
    "\n",
    "# Gradient Descent\n",
    "print(\"Iterating...\")\n",
    "tic = time.time()\n",
    "#W = torch.clone(starting_W)\n",
    "W = starting_W\n",
    "for i in range(nb_steps):\n",
    "    non_local_boxes.evaluate.phi_flat(W, P, Q).backward(gradient=external_grad)\n",
    "    W = projected_wiring(W + learning_rate*W.grad).detach()  # create a brand new tensor, forgeting the previous gradient\n",
    "    W.requires_grad=True\n",
    "toc = time.time()\n",
    "\n",
    "\n",
    "# Result\n",
    "list = non_local_boxes.evaluate.phi_flat(W, P, Q).detach().numpy()\n",
    "print(\"\")\n",
    "print(\"Number of tested wirings: \", len(list))\n",
    "print(\"--> Min: \", min(list))\n",
    "print(\"--> Av.: \", sum(list)/len(list))\n",
    "print(\"--> Max: \", max(list))\n",
    "print(\"Duration: \", (toc-tic)*1e3, \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_boxes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc316f9929218361e7d645a202e8c2b79a1175dfee9b41dd9aa3806e9995da6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
